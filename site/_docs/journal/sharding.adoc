= Transaction data sharding
:page-permalink: /docs/journal/sharding/


Tackler supports journal sharding with both packends (Filesystem and Git),
which means that it is possible to split transaction journal into multiple files.

Splitting transaction data and journals based on single transactions, so that each transaction is 
stored its own file, is also supported. This is the sharding mode tested 
by performance tests, and recommended if transaction data is generated by 
some automated system. In that case it is recommended to use UUIDs as 
xref:./format.adoc[transaction metadata] and use same UUID as part of file name. 

In case that there are some issues with transaction, it will be easier to find.

Example of ISO-8601 date and UUID based filename: `20190117T161930-c91beed3-9489-4d40-bab3-79e72d37800e.txn`



== Sharding schemes 

Two most common shard schemes are time based or topic based sharding.

Example of time based shards: 

 * year/month (e.g. `txns/2019/01/`)
 * year/month/day (e.g. `txns/2019/01/31`)
 * year/iso-week (e.g. `txns/2019/W10`)
 * year/iso-week/iso-week-date (e.g. Monday 2017-01-02 -> `txns/2017/W01/1`)


Example of topic based shards by customers:

 * `txns/Customers/ACME` 
 * `txns/Customers/Initech`


Tackler doesn't care how do you shard or not shard txn data. But sharding makes 
a lot of sense with xref:./git-storage.adoc[Git Storage] backend 
and in case that there is lots of data. If transactions are generated automatically, 
its recommended to use single transaction - single file model and shard data.

Regardless of used sharding scheme, it is possible to group txns by different
`group-by` operators with xref:../report-balance-group.adoc[Balance Group] report.



== Using shards to select subset of transaction data 

Selecting subset of transactions can be by using 
xref:../txn-filters.adoc[Transaction Filters] or by using shards.

The major difference is that by using xref:../txn-filters.adoc[Transaction Filters]
all data is first parsed, and after that filtered.  By using sharding scheme, 
"filtering" happens before journal files are even parsed. On the otherhand, 
sharding lacks all fancy filtering options.

File scanning and glob matching starts from `input.fs.dir` and descents from there.

From performance point of view, sharding is beneficial maybe after 
tens or hundreds of thousands of transactions. This is affect *heavily* by used
Operating System, filesystem and used hardware.  See 
xref:../performance.adoc[Performance Testing] for further details.


=== Example of week based sharding

With data shard and glob-pattern it is very easy to generate reports with
only selected set of accounting data.  For example with shard based on iso-week
it is possible to generate weekly reports with following piece Bash-shell code:

....
report_year=$1
report_week=$2

java \
   -jar tackler-cli.jar \
   --basedir="$exe_dir/.." \
   --input.fs.dir="txns/$report_year/W$report_week" \
   --input.fs.glob="**.txn" \
   "$@"
....


It is possible to combine usage of environment variables with configuration system of Tackler. 

See external documentation of used configuration library for examples and details:
link:https://github.com/typesafehub/config#optional-system-or-env-variable-overrides[Config: system or environment variable overrides].


