= Transaction data sharding
:page-permalink: /docs/journal/sharding/


Tackler supports journal sharding with both packends (Filesystem and Git),
which means that it is possible to split transaction journal into multiple files.

Splitting transaction data and journals based on single transactions, so that each transaction is 
stored its own file, is also supported. This is the sharding mode tested 
by performance tests, and recommended if transaction data is generated by 
some automated system. In that case it is recommended to use UUIDs as 
xref:./format.adoc[transaction metadata] and use that UUID as part of file name.  
For example `20190117T161930-c91beed3-9489-4d40-bab3-79e72d37800e.txn`.



== Sharding schemes 

Two most common shard schemes are time based or topic based sharding.

Example of time based shards: 

 * year/month (e.g. `txns/2019/01/`)
 * year/month/day (e.g. `txns/2019/01/31`)
 * year/iso-week (e.g. `txns/2019/W10`)
 * year/iso-week/iso-week-date (e.g. Monday 2017-01-02 -> `txns/2017/W01/1`)


Example of topic based shards by customers:

 * `txns/Customers/ACME` 
 * `txns/Customers/Initech`


Tackler doesn't care how do you shard or not txn data, but it makes 
a lot of sense with xref:./git-storage.adoc[Git Storage] backend 
and if there is lots of data. If transactions are generated automatically, 
its recommended to use single transaction - single file model and shard data.

Regardless of used sharding scheme, it is possible to group txns with different
`group-by` operators.



== Using shards to select subset of transaction data 

Selecting subset of transactions can be by using 
xref:../txn-filters.adoc[Transaction Filters] or by using shards.

The major difference is that by using xref:../txn-filters.adoc[Transaction Filters]
all data is first parsed, and after that filtered.  By using sharding scheme, 
"filtering" happens before journal files are even parsed. On the otherhand, 
sharding lacks all fancy filtering options.

From performance point of view, sharding is beneficial maybe after 
tens or hundreds of thousands of transactions. See 
xref:../performance.adoc[Performance Testing] for further details.


=== Example of week based sharding

With data shard and glob-pattern it is very easy to generate reports with
only selected set of accounting data.  For example with shard based on iso-week
it is possible to generate weekly reports with following piece Bash-shell code:

....
report_year=$1
report_week=$2

java \
   -jar tackler-cli.jar \
   --basedir="$exe_dir/.." \
   --input.fs.dir="txns/$report_year/W$report_week" \
   --input.fs.glob="**.txn" \
   "$@"
....


It is possible to combine this feature with configuration system of tackler and how  
link:https://github.com/typesafehub/config#optional-system-or-env-variable-overrides[environment arguments are used with configuration]).

File scanning and glob matching starts from `input.fs.dir` and descents from there.

